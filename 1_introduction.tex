\chapter{Introduction} \label{ch:introduction}

In the landscape of unsupervised learning, representation learning plays a pivotal role in distilling complex, high-dimensional data into structured, interpretable, and task-relevant embeddings. Autoencoders (AEs), a class of neural networks trained to reconstruct their inputs, are at the heart of this paradigm. They have been extensively deployed for dimensionality reduction \cite{Goodfellow16}, anomaly detection \cite{Sakurada14}, and denoising \cite{Vincent08}, owing to their ability to capture intrinsic features of the data without relying on labels. However, while the utility of autoencoders in capturing global data structure is well established, there remains a significant blind spot in their representational fidelity, namely, their failure to reliably preserve \textit{in-between instances} (IBIs), which inhabit the transitional regions between clusters.

Traditional approaches to clustering and outlier detection typically adhere to a dichotomy: data points are either inliers, clearly associated with one of several well-separated clusters, or outliers, which are considered noise or statistical anomalies. Yet, real-world datasets often defy such binary classification. In many domains, particularly those characterized by complex, high-dimensional manifolds, such as recommender systems, social networks, and drug discovery, some data points naturally share features with multiple groups. These transitional or hybrid elements, formally referred to as IBIs, are not mere noise. Instead, they convey meaningful inter-cluster information that is vital for downstream tasks \cite{Kazempour24}.

Kazempour et al. (2024) \cite{Kazempour24} introduced the notion of IBIs to address this representational void, defining them as instances that, while not conforming strictly to the prototypes of any single cluster, still exhibit partial affinities with multiple clusters. The presence of IBIs highlights a critical shortcoming of unsupervised embedding methods like vanilla autoencoders, which often prioritize reconstruction fidelity over the preservation of nuanced relational structures in the latent space. When the loss function solely minimizes reconstruction error, embeddings may inadvertently smooth over or collapse the boundaries between clusters, obscuring the subtle topology that IBIs represent.

The importance of preserving IBIs is twofold. First, from a structural perspective, IBIs represent the connective tissue of the dataset, they reveal continuity between discrete groups and often capture transitional phenomena that classical clustering fails to detect. Second, from a practical viewpoint, the ability to identify and preserve IBIs can inform a wide range of applications. For example, in customer analytics, an IBI might represent a user whose behavior spans multiple market segments, indicating a valuable target for cross-promotional strategies. In medical diagnostics, an IBI could reflect a patient exhibiting symptoms from overlapping syndromes, guiding more nuanced clinical assessments.

Despite their importance, IBIs remain underrepresented in the design of autoencoder architectures and training objectives. While sophisticated AE variants such as denoising autoencoders \cite{Vincent08}, sparse autoencoders \cite{Ng11}, and variational autoencoders \cite{Kingma13} have been proposed to address various representational challenges, their enhancements often focus on regularization, generative modeling, or robustness to noise, rather than \textit{explicit preservation of inter-cluster structure}. This thesis addresses this gap by systematically investigating how architectural configurations and loss functions can be tailored to enhance IBI preservation.

Rather than introducing additional architectural complexity, such as employing variational or adversarial enhancements, this work deliberately adopts a controlled approach. By utilizing basic feedforward autoencoders with varied loss functions and minimalistic design choices, the study aims to isolate the impact of specific loss formulations on IBI preservation. This methodological restraint allows for a clear attribution of observed effects to the chosen loss functions, rather than to confounding architectural variables. As such, while sophisticated architectures offer valuable capabilities, they are consciously excluded from the scope of this thesis to maintain a focused investigation into loss-driven representation quality.

The primary research questions guiding this study are as follows:

\begin{itemize}
    \item \textbf{RQ1:} How do different architectural choices in autoencoders affect the preservation of IBIs in the latent space?
    \item \textbf{RQ2:} To what extent does augmenting the reconstruction objective of autoencoders, enhance the model's ability to capture IBIs?
    \item \textbf{RQ3:} How much additional IBI fidelity do supervised metric-learning losses deliver compared to unsupervised configurations?
\end{itemize}

To evaluate the impact of various configurations on IBI preservation, this work employs both quantitative metrics, such as loss-based evaluation, and qualitative assessments through latent space visualizations. The latent representations are constrained to two or three dimensions to enable direct visual inspection, facilitating intuitive and interpretable judgments about cluster separation and the positioning of in-between instances. The central hypothesis is that carefully selected loss functions, particularly when used to augment the standard reconstruction objective, can significantly enhance the model's ability to preserve IBIs. Specifically, this includes the use of \textbf{mean squared error (MSE)} as a baseline reconstruction loss, \textbf{cosine similarity} to encourage angular alignment between inputs and reconstructions, and \textbf{Kullback-Leibler (KL) divergence} to impose distributional consistency. For structure-aware learning, the \textbf{soft trustworthiness loss}, introduced for the first time in this work, provides a differentiable approximation of neighborhood preservation. In supervised configurations, \textbf{triplet margin loss} and \textbf{cosine embedding loss} are employed to enforce metric learning constraints that explicitly promote class-aware separability and semantic coherence in the latent space.
    
The remainder of this thesis is structured as follows. Chapter 2 lays the theoretical groundwork by reviewing autoencoders, and the formal definition of IBIs. Chapter 3 surveys related work, focusing on architectural factors, loss-based structure preservation, and supervised autoencoders. Chapter 4 details the methodological approach, including the datasets, experimental framework, and loss function formulations. Chapter 5 presents the results of empirical experiments, synthesizing findings across research questions. Finally, Chapter 6 concludes with a summary of contributions, limitations, and directions for future research.
